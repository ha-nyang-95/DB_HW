📝 프로젝트 기획 및 진행 보고서
===================

프로젝트명
-----

**실시간 뉴스 수집 및 PostgreSQL 저장 시스템 구축**

* * *

1\. 🎯 프로젝트 개요
--------------

현대 사회에서 정보는 실시간으로 생성되고 확산되며, 특히 뉴스 데이터는 시의성과 신뢰성이 중요한 자산이다. 본 프로젝트는 RSS 피드 기반으로 뉴스 데이터를 실시간 수집하고, 해당 데이터를 웹 크롤링, 자연어 처리(TF-IDF, 임베딩)를 통해 가공한 뒤 PostgreSQL에 저장한다. 이 과정을 통해 데이터 흐름 및 저장 관리 원리를 실습하고, 이후 데이터 분석 및 검색 시스템 개발의 기반을 마련하는 것이 목적이다.

* * *

2\. 🔧 핵심 기능 요약
---------------

*   RSS 피드를 활용한 뉴스 메타데이터 수집 (제목, 링크, 발행일, 카테고리)
    
*   웹 크롤링 기반 본문 및 기자명 수집
    
*   TF-IDF로 핵심 키워드 자동 추출
    
*   KoSBERT 모델을 활용한 문장 임베딩 생성
    
*   PostgreSQL 데이터베이스 연동 및 중복 제거 저장
    
*   전체 흐름에서의 예외처리 및 에러 로깅 적용
    

* * *

3\. 🧩 데이터 수집 및 저장 흐름
---------------------

### 3-1. **RSS 피드 분석 및 수집 자동화**

*   `feedparser` 라이브러리를 사용하여 뉴스 메타데이터 자동 수집
    
*   매일경제 사회면 RSS (`https://www.mk.co.kr/rss/30100041/`) 기준
    
*   각 entry에서 기사 제목, URL, 발행일, 카테고리 추출
    

### 3-2. **뉴스 본문 및 기자명 수집**

*   `requests`, `BeautifulSoup`을 사용한 HTML 크롤링
    
*   `<div class="news_cnt_detail_wrap">` 내부 `p` 태그 활용
    
*   `figcaption`, `author` 영역 등을 통해 다양한 기사 포맷 대응
    

### 3-3. **콘텐츠 정제 및 분석**

*   TF-IDF 기반 키워드 추출 (`TfidfVectorizer`)
    
    *   불용어 제거 및 score 기반으로 상위 키워드 선택
        
*   KoSBERT 임베딩 생성 (`jhgan/ko-sbert-nli`)
    
    *   후속 추천·유사도 분석, 클러스터링 기반 검색 시스템 확장 가능
        

### 3-4. **데이터베이스 저장**

*   `psycopg2`를 이용해 PostgreSQL 연동
    
*   URL 기준 중복 체크 후 저장 여부 결정
    
*   키워드(JSON) 및 임베딩(Vector List)을 포함한 정형 저장
    

* * *

4\. 💾 DB 테이블 설계 (news\_article)
--------------------------------

| 필드명 | 타입 | 설명 |
| --- | --- | --- |
| id | SERIAL (PK) | 고유 ID |
| title | TEXT | 기사 제목 |
| writer | TEXT | 작성 기자 |
| write\_date | TIMESTAMP | 발행일 |
| category | TEXT | 카테고리 |
| content | TEXT | 본문 내용 |
| url | TEXT | 기사 링크 (중복 체크 기준) |
| keywords | JSON | TF-IDF 기반 키워드 리스트 |
| embedding | FLOAT\[\] | KoSBERT 임베딩 벡터 |

> 🔐 데이터 무결성 확보를 위해 `url`에 Unique 제약 조건 권장

* * *

5\. 🛠 기술 스택 및 도구
-----------------

| 분류 | 도구/기술 | 설명 |
| --- | --- | --- |
| 언어 | Python 3 | 전체 프로세스 구현 |
| 크롤링 | feedparser, BeautifulSoup, requests | RSS 및 웹 콘텐츠 수집 |
| 분석 | scikit-learn, sentence-transformers | 키워드 및 임베딩 처리 |
| DB | PostgreSQL, psycopg2 | 데이터 저장소 |
| 보안 | dotenv | DB 정보 등 환경 변수 관리 |

* * *

6\. 📈 전체 프로세스 흐름도
------------------

```markdown
1. RSS 피드 수집
   └─> 2. 기사 링크 수집
        └─> 3. 본문 및 기자명 크롤링
              ├─> 4. TF-IDF 키워드 추출
              └─> 5. 문장 임베딩 생성
                   └─> 6. 중복 확인 및 DB 저장

```

* * *

7\. 📌 실행 절차
------------

```bash
# 1. .env 파일에 PostgreSQL 정보 기입
DB_USERNAME=your_id
DB_PASSWORD=your_pw

# 2. 실행
python main.py
```

* * *

8\. ✅ 기대 효과 및 학습 성과
-------------------

### 🎯 실무 적용

*   실제 뉴스 데이터를 대상으로 ETL 흐름을 학습함으로써 **데이터 파이프라인의 기초 역량** 확보
    
*   DB 연동을 통해 **데이터 무결성과 저장 관리 이론을 실전 적용**
    

### 🧠 기술 내재화

*   자연어 처리에서 **키워드 추출과 임베딩 개념 실습**
    
*   다양한 HTML 구조에 대응하는 **웹 크롤링 로직 설계 능력 향상**
    
*   예외처리, 중복 제거, 환경 변수 관리 등 **서비스화 고려 프로그래밍 습득**
    

* * *

9\. 🔭 확장 가능성
----------------

| 확장 방향 | 설명 |
| --- | --- |
| 뉴스 검색 시스템 | 임베딩 벡터를 활용한 유사 기사 추천 가능 |
| 대시보드 시각화 | 수집된 뉴스의 키워드 및 카테고리별 통계 분석 |
| 크롤러 스케줄링 | `cron`, `Airflow` 등을 통한 주기적 자동화 가능 |
| 다중 피드 수집 | 다양한 언론사 RSS 피드 통합 수집 및 비교 분석 |

* * *

✨ 부록: 참고 기술 링크
--------------

*   feedparser 문서
    
*   BeautifulSoup4 문서
    
*   KoSBERT 모델
    
*   TF-IDF 개념