# PyFlink 설치 가이드

🧠 PyFlink 과제 정리본 (비전공자용)
=========================

* * *

1\. 📌 과제 개요
------------

**목표**:  
CSV로 주어진 금융 거래 데이터를 분석하여, 각 거래 유형(`입금`, `출금`, `구매` 등)별로 **총 거래 금액을 집계**하는 것이 목표입니다.

이 데이터를 스트림 방식으로 처리하기 위해 **Apache Flink**와 \*\*PyFlink(Python용 Flink API)\*\*를 사용합니다.

* * *

2\. 🧰 사전 준비 단계 (처음 환경 설정)
--------------------------

### ✅ 1) 가상환경 만들기 (Python 전용 작업 공간)

```bash
sudo apt update
sudo apt install python3-venv  # 가상환경 설치
mkdir ~/flink_project && cd ~/flink_project  # 작업 폴더 생성
python3 -m venv venv          # 가상환경 만들기
source venv/bin/activate      # 가상환경 실행
```

### ✅ 2) 필요한 패키지 설치

```bash
pip install apache-flink pandas
```

> ✅ 설치 확인

```bash
python
>>> import pandas
>>> from pyflink.datastream import StreamExecutionEnvironment
>>> exit()
```

* * *

3\. ⚙️ Flink 설치 및 실행 설정
-----------------------

### ✅ 1) Flink 설치

```bash
cd ~
wget https://downloads.apache.org/flink/flink-1.20.0/flink-1.20.0-bin-scala_2.12.tgz
tar -xvzf flink-1.20.0-bin-scala_2.12.tgz
sudo mv flink-1.20.0 /usr/local/flink-1.20.0
```

### ✅ 2) 환경 변수 설정

```bash
export FLINK_HOME=/usr/local/flink-1.20.0
export PATH=$FLINK_HOME/bin:$PATH
source ~/.bashrc
```

* * *

4\. 📂 CSV 파일 예시
----------------

`data.csv` 파일 내용은 다음과 같이 구성되어 있습니다.

```csv
transaction_type,amount
입금,10000
출금,5000
입금,3000
구매,7000
입금,9000
```

* * *

5\. 💻 코드 설명 (`skeleton.py`)
----------------------------

아래 코드는 PyFlink를 이용해 CSV 데이터를 읽고, 각 거래 유형별 총 금액을 계산하는 코드입니다.

```python
import pandas as pd
from pyflink.datastream import StreamExecutionEnvironment
from pyflink.common.typeinfo import Types

def main():
    # 1. Flink 실행 환경 설정
    env = StreamExecutionEnvironment.get_execution_environment()
    env.set_parallelism(2)  # 병렬 처리 수준 (2개의 스레드 사용)

    # 2. CSV 데이터 불러오기 + 전처리
    df = pd.read_csv("./data/data.csv")  # CSV 불러오기
    df = df[['transaction_type', 'amount']].dropna()  # 결측치 제거
    df['amount'] = df['amount'].astype(int)           # 금액을 int로 변환
    transactions = df.values.tolist()                 # 2차원 리스트로 변환

    # 3. 리스트 데이터를 Flink 스트림으로 변환
    transaction_stream = env.from_collection(
        transactions,
        type_info=Types.TUPLE([Types.STRING(), Types.INT()])
    )

    # 4. 거래 유형별로 그룹핑 후 금액 합산
    transaction_total = (
        transaction_stream
        .key_by(lambda x: x[0])  # 거래 유형 기준 그룹핑
        .reduce(lambda a, b: (a[0], a[1] + b[1]))  # 금액 합산
    )

    # 5. 결과 출력
    transaction_total.print()

    # 6. Flink 실행 명령어
    env.execute("Transaction Type Aggregation")

if __name__ == "__main__":
    main()
```

* * *

6\. ▶️ 실행 방법
------------

### ✅ 터미널에서 실행

```bash
export FLINK_HOME=/usr/local/flink-1.20.0
$FLINK_HOME/bin/flink run -py skeleton.py
```

### ✅ 실행 결과 예시

(정상적으로 실행되면 아래와 같이 결과가 터미널에 나올 수 있습니다)

```
(banks, 40000)
(cash, 12000)
(deposit, 19000)
...
```

* * *

7\. 🧩 자주 나오는 에러와 해결법
---------------------

| 에러 메시지 | 원인 및 해결 방법 |
| --- | --- |
| `Field 1 is null` | CSV에 결측치가 있어서 → `dropna()`와 `astype(int)`로 처리 |
| `cannot serialize` | 리스트에 `None` 포함 시 발생 → 위와 동일 |
| `ModuleNotFoundError` | `pandas` 혹은 `pyflink` 설치 안 됨 → `pip install`로 설치 |
| 결과가 안 보임 | `print()` 결과가 안 나오는 경우 있음 → FileSink로 파일 저장 권장 |

* * *

8\. 📁 결과 파일로 저장하기 (선택 사항)
--------------------------

터미널에 결과가 안 보이면, 아래처럼 파일로 저장해도 됩니다:

```python
from pyflink.datastream.connectors import StreamingFileSink
from pyflink.common.serialization import SimpleStringEncoder
from pyflink.datastream import FileSink, OutputFileConfig

# 문자열로 변환 후 출력 저장
sink = FileSink \
    .for_row_format("./output", SimpleStringEncoder()) \
    .with_output_file_config(OutputFileConfig.builder().with_part_prefix("result").build()) \
    .build()

transaction_total.map(lambda x: str(x), output_type=Types.STRING()).sink_to(sink)
```

→ 실행 후 `output/` 폴더에 결과가 저장됩니다.

* * *

9\. 🔑 핵심 개념 정리
---------------

| 용어 | 의미 |
| --- | --- |
| `StreamExecutionEnvironment` | Flink에서 스트림 작업을 위한 환경 설정 객체 |
| `from_collection()` | 리스트 데이터를 Flink 스트림으로 변환 |
| `key_by()` | 특정 값을 기준으로 그룹핑 (여기선 거래 유형) |
| `reduce()` | 그룹 내 값들을 누적 (여기선 금액 합산) |
| `print()` | 실행 결과를 콘솔에 출력 |
| `env.execute()` | Flink 프로그램 실행 시작 |

* * *

✅ 마무리 요약
--------

*   CSV → pandas로 불러오기
    
*   NaN 제거, int로 변환
    
*   리스트 → Flink 스트림 변환
    
*   key\_by로 그룹핑, reduce로 누적합
    
*   결과 출력 or 파일 저장
    
*   Flink 실행 (`flink run -py 파일명.py`)
    

* * *

필요하시면 이 내용을 PDF나 Markdown으로 정리해드릴 수도 있어요!  
추가적으로 궁금한 내용이나 모호한 부분 있으면 얼마든지 물어보세요 :)



---
Powered by [ChatGPT Exporter](https://www.chatgptexporter.com)