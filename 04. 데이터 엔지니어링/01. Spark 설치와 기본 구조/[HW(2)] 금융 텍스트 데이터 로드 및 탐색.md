ğŸ“˜ ê¸ˆìœµ í…ìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ë° íƒìƒ‰
=========================

> ì´ ë¬¸ì„œëŠ” PySparkë¥¼ ì‚¬ìš©í•´ í…ìŠ¤íŠ¸ íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ê³ , ë°ì´í„°ë¥¼ íƒìƒ‰ ë° ë³€í™˜í•˜ëŠ” ì‹¤ìŠµ ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•œ ìë£Œì…ë‹ˆë‹¤. ë¹„ì „ê³µìë„ Spark ê°œë…ì„ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ êµ¬ì„±í•˜ì˜€ìŠµë‹ˆë‹¤.

* * *

âœ… 1. í™˜ê²½ ì„¤ì •
----------

```python
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("TextDataAnalysis").getOrCreate()
sc = spark.sparkContext
```

### ğŸ’¡ ê°œë… ì„¤ëª…

*   **SparkSession**: Spark ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì‹œì‘ì ì…ë‹ˆë‹¤. DataFrameì´ë‚˜ SQL ì—°ì‚°ì— ì‚¬ìš©ë©ë‹ˆë‹¤.
    
*   **SparkContext**: ì €ìˆ˜ì¤€ APIì¸ RDD(Resilient Distributed Dataset)ë¥¼ ì œì–´í•˜ê¸° ìœ„í•œ ì§„ì…ì ì…ë‹ˆë‹¤.
    
*   **`.appName()`**: ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì´ë¦„ì„ ì§€ì •í•©ë‹ˆë‹¤. ë¡œê·¸ë‚˜ UIì—ì„œ í‘œì‹œë©ë‹ˆë‹¤.
    

* * *

âœ… 2. í…ìŠ¤íŠ¸ íŒŒì¼ ë¡œë“œ
--------------

```python
text_data = sc.textFile("../data/test_1.txt")
```

*   **`textFile()`**: í…ìŠ¤íŠ¸ íŒŒì¼ì„ í•œ ì¤„ì”© ì½ì–´ RDDë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
*   ê° ì¤„ì€ í•˜ë‚˜ì˜ ë¬¸ìì—´(string)ë¡œ ì´ë£¨ì–´ì ¸ ìˆìœ¼ë©°, RDDì˜ í•œ ìš”ì†Œê°€ ë©ë‹ˆë‹¤.
    

* * *

âœ… 3. ì „ì²´ ë°ì´í„° í™•ì¸
--------------

```python
print(text_data.collect())
```

*   **`collect()`**: ì „ì²´ RDD ë°ì´í„°ë¥¼ ë“œë¼ì´ë²„ í”„ë¡œê·¸ë¨ìœ¼ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    
*   ì‘ì€ ë°ì´í„°ì…‹ì—ì„œë§Œ ì‚¬ìš©í•´ì•¼ í•˜ë©°, ì¶œë ¥ ì‹œ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë°˜í™˜ë©ë‹ˆë‹¤.
    

### ğŸ“ ì˜ˆì‹œ ì¶œë ¥

```text
[
 'The worldâ€™s most valuable resource is no longer oil, but data.',
 'Big Data and AI are transforming industries worldwide.',
 'Companies are investing heavily in real-time analytics.'
]
```

* * *

âœ… 4. ì¤„ ìˆ˜ ì„¸ê¸° (í–‰ ê°œìˆ˜)
------------------

```python
print("ì „ì²´ ì¤„ ê°œìˆ˜:", text_data.count())
```

*   **`count()`**: ì „ì²´ RDD ìš”ì†Œ(=ì¤„)ì˜ ê°œìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
*   ì˜ˆì‹œ ë°ì´í„°ëŠ” 3ì¤„ì´ë¯€ë¡œ ì¶œë ¥ ê²°ê³¼ëŠ” `3`.
    

* * *

âœ… 5. íŠ¹ì • ë‹¨ì–´ê°€ í¬í•¨ëœ ì¤„ í•„í„°ë§
---------------------

```python
contains_data = text_data.filter(lambda line: 'data' in line.lower())
```

### ğŸ’¡ ê°œë… ì„¤ëª…

*   **`filter()`**: ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ë§Œ ê±¸ëŸ¬ëƒ…ë‹ˆë‹¤.
    
*   ì—¬ê¸°ì„œëŠ” ê° ì¤„ì„ ëª¨ë‘ ì†Œë¬¸ìë¡œ ë°”ê¾¼ ë’¤, `'data'`ë¼ëŠ” ë‹¨ì–´ê°€ í¬í•¨ëœ ê²½ìš°ë§Œ ë‚¨ê¹ë‹ˆë‹¤.
    
*   **`in` ì—°ì‚°ì**ëŠ” ë¬¸ìì—´ í¬í•¨ ì—¬ë¶€ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
    

```python
print(contains_data.collect())
print("ì „ì²´ ì¤„ ê°œìˆ˜:", contains_data.count())
```

*   í•„í„°ë§ëœ ì¤„ë§Œ ì¶œë ¥ë˜ê³ , ëª‡ ì¤„ì¸ì§€ë„ í•¨ê»˜ í™•ì¸í•©ë‹ˆë‹¤.
    

* * *

âœ… 6. ëŒ€ì†Œë¬¸ì ë³€í™˜
------------

### ëŒ€ë¬¸ìë¡œ ë³€í™˜

```python
upper_case_data = text_data.map(lambda line: line.upper())
print(upper_case_data.collect())
```

*   **`map()`**: RDDì˜ ê° ìš”ì†Œì— í•¨ìˆ˜ë¥¼ ì ìš©í•´ ìƒˆë¡œìš´ RDDë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
*   **`.upper()`**: ë¬¸ìì—´ì„ ëª¨ë‘ ëŒ€ë¬¸ìë¡œ ë°”ê¾¸ëŠ” íŒŒì´ì¬ ë¬¸ìì—´ í•¨ìˆ˜ì…ë‹ˆë‹¤.
    

### ì†Œë¬¸ìë¡œ ë³€í™˜

```python
lower_case_data = text_data.map(lambda line: line.lower())
print(lower_case_data.collect())
```

*   **`.lower()`**: ë¬¸ìì—´ì„ ëª¨ë‘ ì†Œë¬¸ìë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    

* * *

âœ… 7. íŒŒí‹°ì…˜ ê°œìˆ˜ í™•ì¸ ë° ì¬ë¶„í• 
--------------------

```python
print("ê¸°ë³¸ íŒŒí‹°ì…˜ ê°œìˆ˜:", text_data.getNumPartitions())
```

*   **`getNumPartitions()`**: RDDê°€ ë¶„ì‚°ë˜ì–´ ìˆëŠ” íŒŒí‹°ì…˜ì˜ ìˆ˜ë¥¼ ì•Œë ¤ì¤ë‹ˆë‹¤.
    
*   SparkëŠ” ë°ì´í„°ë¥¼ ìë™ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì—¬ëŸ¬ ì»´í“¨í„°ë‚˜ CPU ì½”ì–´ì—ì„œ ë³‘ë ¬ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
    
*   ê¸°ë³¸ì ìœ¼ë¡œëŠ” ì‹¤í–‰ í™˜ê²½ì— ë”°ë¼ íŒŒí‹°ì…˜ ìˆ˜ê°€ ì •í•´ì§‘ë‹ˆë‹¤ (ì˜ˆ: 2ê°œ).
    

* * *

### íŒŒí‹°ì…˜ ìˆ˜ ì¬ì„¤ì •

```python
repartitioned_data = text_data.repartition(4)
print("ë³€ê²½ëœ íŒŒí‹°ì…˜ ê°œìˆ˜:", repartitioned_data.getNumPartitions())
```

*   **`repartition(n)`**: íŒŒí‹°ì…˜ ìˆ˜ë¥¼ ê°•ì œë¡œ ë³€ê²½í•©ë‹ˆë‹¤.
    
*   ì˜ˆë¥¼ ë“¤ì–´, ë°ì´í„°ë¥¼ 4ê°œì˜ íŒŒí‹°ì…˜ìœ¼ë¡œ ë‚˜ëˆ„ë©´ ë” ë§ì€ ë³‘ë ¬ ì²˜ë¦¬ê°€ ê°€ëŠ¥í•´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    
*   **ì£¼ì˜**: ë„ˆë¬´ ë§ì€ íŒŒí‹°ì…˜ì€ ì˜¤íˆë ¤ ì„±ëŠ¥ì„ ì €í•˜ì‹œí‚¬ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì ì ˆí•œ ìˆ˜ ì¡°ì •ì´ ì¤‘ìš”í•©ë‹ˆë‹¤.
    
* * *

âœ… 8. ì „ì²´ ì½”ë“œ
--------------------
```python
from pyspark.sql import SparkSession

# SparkSession ìƒì„±
spark = SparkSession.builder.appName("TextDataAnalysis").getOrCreate()
sc = spark.sparkContext

# í…ìŠ¤íŠ¸ íŒŒì¼ ë¡œë“œ
text_data = sc.textFile("../data/test_1.txt")

# ì „ì²´ í…ìŠ¤íŠ¸ ì¶œë ¥
# ['The worldâ€™s most valuable resource is no longer oil, but data.', 
#  'Big Data and AI are transforming industries worldwide.', 
#  'Companies are investing heavily in real-time analytics.']
print(text_data.collect())

# ì¤„ ìˆ˜ ì¶œë ¥
# ì „ì²´ ì¤„ ê°œìˆ˜: 3
print("ì „ì²´ ì¤„ ê°œìˆ˜:", text_data.count())

# 'data'ê°€ í¬í•¨ëœ ë¬¸ì¥ í•„í„°ë§
# ['The worldâ€™s most valuable resource is no longer oil, but data.', 
#  'Big Data and AI are transforming industries worldwide.']
contains_data = text_data.filter(lambda line: 'data' in line.lower())
print(contains_data.collect())

# í¬í•¨ëœ ì¤„ ìˆ˜ ì¶œë ¥
# ì „ì²´ ì¤„ ê°œìˆ˜: 2
print("ì „ì²´ ì¤„ ê°œìˆ˜:", contains_data.count())

# ëŒ€ë¬¸ìë¡œ ë³€í™˜
# ['THE WORLDâ€™S MOST VALUABLE RESOURCE IS NO LONGER OIL, BUT DATA.', 
#  'BIG DATA AND AI ARE TRANSFORMING INDUSTRIES WORLDWIDE.', 
#  'COMPANIES ARE INVESTING HEAVILY IN REAL-TIME ANALYTICS.']
upper_case_data = text_data.map(lambda line: line.upper())
print(upper_case_data.collect())

# ì†Œë¬¸ìë¡œ ë³€í™˜
# ['the worldâ€™s most valuable resource is no longer oil, but data.', 
#  'big data and ai are transforming industries worldwide.', 
#  'companies are investing heavily in real-time analytics.']
lower_case_data = text_data.map(lambda line: line.lower())
print(lower_case_data.collect())

# ê¸°ë³¸ íŒŒí‹°ì…˜ ê°œìˆ˜ í™•ì¸
# ê¸°ë³¸ íŒŒí‹°ì…˜ ê°œìˆ˜: 2
print("ê¸°ë³¸ íŒŒí‹°ì…˜ ê°œìˆ˜:", text_data.getNumPartitions())

# íŒŒí‹°ì…˜ 4ê°œë¡œ ì¬ì„¤ì • í›„ í™•ì¸
# ë³€ê²½ëœ íŒŒí‹°ì…˜ ê°œìˆ˜: 4
repartitioned_data = text_data.repartition(4)
print("ë³€ê²½ëœ íŒŒí‹°ì…˜ ê°œìˆ˜:", repartitioned_data.getNumPartitions())
```
* * *

ğŸ“Œ ì£¼ìš” ê°œë… ìš”ì•½
-----------

| ê°œë… | ì„¤ëª… | ê´€ë ¨ í•¨ìˆ˜ |
| --- | --- | --- |
| **RDD** | ë¶„ì‚°ëœ ë°ì´í„° ì§‘í•© | `sc.textFile()`, `map()`, `filter()` |
| **Transformation** | ìƒˆë¡œìš´ RDD ìƒì„±. ì§€ì—° í‰ê°€ë¨ | `map()`, `filter()`, `repartition()` |
| **Action** | ì‹¤ì œ ê²°ê³¼ ë°˜í™˜, ì‹¤í–‰ íŠ¸ë¦¬ê±° | `count()`, `collect()` |
| **lambda í•¨ìˆ˜** | ìµëª… í•¨ìˆ˜ ì •ì˜ ë¬¸ë²• | `lambda x: x.upper()` |
| **ëŒ€ì†Œë¬¸ì ì²˜ë¦¬** | ë¬¸ìì—´ ë©”ì„œë“œ ì‚¬ìš© | `.upper()`, `.lower()` |
| **íŒŒí‹°ì…”ë‹** | ë°ì´í„°ë¥¼ ë‚˜ëˆ  ë³‘ë ¬ ì²˜ë¦¬ | `getNumPartitions()`, `repartition()` |

* * *

ğŸ§  ì‹¤ìŠµì„ í†µí•´ ì–»ëŠ” ì—­ëŸ‰
---------------

*   í…ìŠ¤íŠ¸ íŒŒì¼ì„ RDDë¡œ ë¶ˆëŸ¬ì˜¤ëŠ” ë°©ë²• í•™ìŠµ
    
*   `filter`, `map`, `count` ë“±ì˜ ê¸°ë³¸ RDD ì—°ì‚° ìµíˆê¸°
    
*   ë¬¸ìì—´ ì²˜ë¦¬ (ëŒ€ì†Œë¬¸ì ë³€í™˜)ì™€ ì¡°ê±´ í•„í„°ë§ ì‹¤ìŠµ
    
*   íŒŒí‹°ì…”ë‹ ê°œë…ê³¼ ë³‘ë ¬ ì²˜ë¦¬ ê°ê° ìµíˆê¸°
