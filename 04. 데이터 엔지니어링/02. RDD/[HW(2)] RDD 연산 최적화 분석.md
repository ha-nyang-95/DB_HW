ğŸ“˜ RDD ì—°ì‚° ìµœì í™” ì‹¤ìŠµ ì •ë¦¬ë³¸
====================

âœ¨ ì‹¤ìŠµ ëª©í‘œ
-------

*   Spark RDDì—ì„œì˜ `map()`, `filter()`, `flatMap()`, `mapPartitions()` ì—°ì‚°ì„ ë¹„êµí•œë‹¤.
    
*   ë™ì¼í•œ ê²°ê³¼ë¥¼ ë§Œë“œëŠ” ì—¬ëŸ¬ ì—°ì‚° ë°©ì‹ì˜ **ì„±ëŠ¥ ì°¨ì´**ë¥¼ ì§ì ‘ ì²´ê°í•œë‹¤.
    
*   `mapPartitions()`ê³¼ ê°™ì€ ê³ ê¸‰ ì—°ì‚°ì˜ **íš¨ìœ¨ì„±**ì„ ì´í•´í•œë‹¤.
    

* * *

ğŸ“Œ 1. SparkContext ìƒì„±
---------------------

```python
from pyspark import SparkContext
import time
sc = SparkContext("local", "RDDOptimization")
```

*   **SparkContext**ëŠ” Spark ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‹œì‘í•˜ëŠ” í•µì‹¬ ê°ì²´ì´ë©°,
    
*   `"local"`ì€ ë¡œì»¬ ë¨¸ì‹ ì—ì„œ ì‹¤í–‰í•¨ì„ ì˜ë¯¸í•˜ê³ ,
    
*   `"RDDOptimization"`ì€ ì• í”Œë¦¬ì¼€ì´ì…˜ ì´ë¦„ì´ë‹¤.
    

* * *

ğŸ“Œ 2. RDD ìƒì„±
------------

```python
num_partitions = 8
rdd = sc.parallelize(range(1, 1000001), num_partitions)
```

*   `parallelize(data, num_partitions)`: ë°ì´í„°ë¥¼ RDDë¡œ ë§Œë“¤ê³  **8ê°œì˜ íŒŒí‹°ì…˜**ìœ¼ë¡œ ë‚˜ëˆ”.
    
*   ì—¬ê¸°ì„œëŠ” **1ë¶€í„° 1,000,000ê¹Œì§€** ìˆ«ìë¥¼ ê°€ì§„ RDDë¥¼ ìƒì„±í•¨.
    

* * *

ğŸ“Œ 3. ì‹œê°„ ì¸¡ì • í•¨ìˆ˜
--------------

```python
def measure_time(fn):
    start = time.time()
    result = fn()
    end = time.time()
    return result, end - start
```

*   ì–´ë–¤ ì—°ì‚° í•¨ìˆ˜ `fn`ì„ ì‹¤í–‰í•˜ê³  **ê±¸ë¦° ì‹œê°„**ì„ ì¸¡ì •í•´ì„œ ë°˜í™˜í•˜ëŠ” ìœ í‹¸ í•¨ìˆ˜.
    

* * *

ğŸ“Œ 4. map + filter ë°©ì‹
---------------------

```python
rdd.filter(lambda x: x % 2 == 0).map(lambda x: x * 2).collect()
```

### âœ… ë™ì‘ ì„¤ëª…

*   ë¨¼ì € `filter()`ë¡œ **ì§ìˆ˜ë§Œ í•„í„°ë§** â†’ ì•½ 500,000ê°œ
    
*   ì´í›„ `map()`ìœ¼ë¡œ **2ë°° ì—°ì‚°** ìˆ˜í–‰
    
*   `.collect()`ë¡œ ê²°ê³¼ë¥¼ **ë“œë¼ì´ë²„ë¡œ ê°€ì ¸ì˜´**
    

### ğŸ” ê²°ê³¼ ì˜ˆì‹œ

```python
[map + filter] ê°œìˆ˜: 500000
[map + filter] ìƒ˜í”Œ: [4, 8, 12, 16, 20]
[map + filter] ì‹œê°„: 1.3814 ì´ˆ
```

### ğŸ“Œ ë¹„íš¨ìœ¨ì ì¸ ì´ìœ 

*   `filter()`ì™€ `map()`ì„ **ë³„ë„ë¡œ ì‹¤í–‰** â†’ ì—°ì‚° ì˜¤ë²„í—¤ë“œ ë°œìƒ
    
*   ê° ìš”ì†Œì— ëŒ€í•´ ë‘ ë²ˆì˜ í•¨ìˆ˜ í˜¸ì¶œì´ í•„ìš”í•¨ (í•¨ìˆ˜ í˜¸ì¶œ ë¹„ìš©)
    

* * *

ğŸ“Œ 5. flatMap ë°©ì‹
----------------

```python
rdd.flatMap(lambda x: [x * 2] if x % 2 == 0 else []).collect()
```

### âœ… ë™ì‘ ì„¤ëª…

*   í•œ ë²ˆì˜ ì—°ì‚°ìœ¼ë¡œ `ì§ìˆ˜ì´ë©´ [x*2]`, í™€ìˆ˜ì´ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    
*   ê²°ê³¼ì ìœ¼ë¡œ ì§ìˆ˜ë§Œ ê±¸ëŸ¬ì§€ê³  2ë°° ì²˜ë¦¬ëœ ê°’ë§Œ ë‚¨ìŒ
    
*   `map + filter`ë¥¼ **í•œ ì¤„ë¡œ í†µí•©**í•œ ì…ˆ
    

### ğŸ” ê²°ê³¼ ì˜ˆì‹œ

```python
[flatMap] ê°œìˆ˜: 500000
[flatMap] ìƒ˜í”Œ: [4, 8, 12, 16, 20]
[flatMap] ì‹œê°„: 0.8412 ì´ˆ
```

### ğŸ“Œ ì¥ì 

*   í•¨ìˆ˜ í˜¸ì¶œì´ **1íšŒë¡œ ì¤„ì–´ë“¦**
    
*   ì¡°ê±´ ë¶„ê¸°ì™€ ë³€í™˜ì„ **ë™ì‹œì— ìˆ˜í–‰**
    
*   ì²˜ë¦¬ ì†ë„ ê°œì„ 
    

* * *

ğŸ“Œ 6. mapPartitions ë°©ì‹
----------------------

```python
def transform_partition(iterator):
    return (x * 2 for x in iterator if x % 2 == 0)

rdd.mapPartitions(transform_partition).collect()
```

### âœ… ë™ì‘ ì„¤ëª…

*   **ê° íŒŒí‹°ì…˜ ë‹¨ìœ„ë¡œ** ë°ì´í„°ë¥¼ ì²˜ë¦¬í•¨.
    
*   ë§¤ íŒŒí‹°ì…˜ë§ˆë‹¤ ë°˜ë³µì(`iterator`)ê°€ ì£¼ì–´ì§€ë©°,
    
*   ê·¸ ì•ˆì—ì„œ ì§ìˆ˜ë¥¼ í•„í„°ë§í•˜ê³  2ë°° ì²˜ë¦¬ëœ ê°’ë§Œ ë°˜í™˜.
    

### ğŸ” ê²°ê³¼ ì˜ˆì‹œ

```python
[mapPartitions] ê°œìˆ˜: 500000
[mapPartitions] ìƒ˜í”Œ: [4, 8, 12, 16, 20]
[mapPartitions] ì‹œê°„: 0.7741 ì´ˆ
```

### ğŸ“Œ ê°€ì¥ íš¨ìœ¨ì ì¸ ì´ìœ 

*   **íŒŒí‹°ì…˜ ë‹¨ìœ„ë¡œ ì—°ì‚°ì„ ìˆ˜í–‰**í•˜ë¯€ë¡œ, ë§¤ ìš”ì†Œë§ˆë‹¤ í•¨ìˆ˜ í˜¸ì¶œí•˜ëŠ” `map`ë³´ë‹¤ íš¨ìœ¨ì 
    
*   ë©”ëª¨ë¦¬ ì‚¬ìš©ê³¼ CPU í˜¸ì¶œì´ ê°ì†Œ â†’ ì†ë„ ê°œì„ 
    

* * *

ğŸ“Œ 7. ì „ì²´ ì½”ë“œ
----------------------

```python
from pyspark import SparkContext
import time
sc = SparkContext("local", "RDDOptimization")

# 1. íŒŒí‹°ì…˜ ê°œìˆ˜ ì§€ì •
num_partitions = 8

# 2. 1~1,000,000ê¹Œì§€ì˜ ìˆ«ì ë°ì´í„°ë¥¼ í¬í•¨í•˜ëŠ” RDD ìƒì„±
rdd = sc.parallelize(range(1, 1000001), num_partitions)

# 3. ìˆ˜í–‰ ì‹œê°„ ì¸¡ì • í•¨ìˆ˜ ì •ì˜
def measure_time(fn):
    start = time.time()
    result = fn()
    end = time.time()
    return result, end - start

# 4. map+filter ì—°ì‚°
# [map + filter] ê°œìˆ˜: 500000                                                     
# [map + filter] ìƒ˜í”Œ: [4, 8, 12, 16, 20]
# [map + filter] ì‹œê°„: 1.3814 ì´ˆ
map_filter_result, t1 = measure_time(lambda: rdd.filter(lambda x: x % 2 == 0).map(lambda x: x * 2).collect())
print("[map + filter] ê°œìˆ˜:", len(map_filter_result))
print("[map + filter] ìƒ˜í”Œ:", map_filter_result[:5])
print("[map + filter] ì‹œê°„:", round(t1, 4), "ì´ˆ")

# 5. flatMap ì—°ì‚°
# [flatMap] ê°œìˆ˜: 500000                                                          
# [flatMap] ìƒ˜í”Œ: [4, 8, 12, 16, 20]
# [flatMap] ì‹œê°„: 0.8412 ì´ˆ
flatmap_result, t2 = measure_time(lambda: rdd.flatMap(lambda x: [x * 2] if x % 2 == 0 else []).collect())
print("[flatMap] ê°œìˆ˜:", len(flatmap_result))
print("[flatMap] ìƒ˜í”Œ:", flatmap_result[:5])
print("[flatMap] ì‹œê°„:", round(t2, 4), "ì´ˆ")

# 6. mapPartitions ì—°ì‚°
# [mapPartitions] ê°œìˆ˜: 500000                                                    
# [mapPartitions] ìƒ˜í”Œ: [4, 8, 12, 16, 20]
# [mapPartitions] ì‹œê°„: 0.7741 ì´ˆ
def transform_partition(iterator):
    return (x * 2 for x in iterator if x % 2 == 0)

mappart_result, t3 = measure_time(lambda: rdd.mapPartitions(transform_partition).collect())
print("[mapPartitions] ê°œìˆ˜:", len(mappart_result))
print("[mapPartitions] ìƒ˜í”Œ:", mappart_result[:5])
print("[mapPartitions] ì‹œê°„:", round(t3, 4), "ì´ˆ")
```
* * *

ğŸ“Š ì„±ëŠ¥ ë¹„êµ ìš”ì•½í‘œ
------------

| ì—°ì‚° ë°©ì‹       | ì²˜ë¦¬ ë°©ì‹                   | í•¨ìˆ˜ í˜¸ì¶œ ìˆ˜ | ì¥ì               | ë‹¨ì                        | ì†Œìš” ì‹œê°„ (ì˜ˆì‹œ) |
| --------------- | --------------------------- | ------------ | ----------------- | -------------------------- | ---------------- |
| `map + filter`  | ìš”ì†Œ ë‹¨ìœ„ë¡œ 2ë‹¨ê³„ ì²˜ë¦¬      | 2íšŒ/ìš”ì†Œ     | ì½”ë“œê°€ ì§ê´€ì      | ëŠë¦¼, ë¹„íš¨ìœ¨ì              | 1.38ì´ˆ           |
| `flatMap`       | ìš”ì†Œ ë‹¨ìœ„ë¡œ 1ë‹¨ê³„ í†µí•© ì²˜ë¦¬ | 1íšŒ/ìš”ì†Œ     | íš¨ìœ¨ì , ë¹ ë¦„      | ê°€ë…ì„±ì´ ì‚´ì§ ë‚®ì„ ìˆ˜ ìˆìŒ | 0.84ì´ˆ           |
| `mapPartitions` | íŒŒí‹°ì…˜ ë‹¨ìœ„ë¡œ ì¼ê´„ ì²˜ë¦¬     | 1íšŒ/íŒŒí‹°ì…˜   | ê°€ì¥ ë¹ ë¦„, ê³ ì„±ëŠ¥ | ë³µì¡í•œ ë¡œì§ êµ¬í˜„ ì‹œ ì£¼ì˜   | 0.77ì´ˆ           |

* * *

ğŸ§  í•µì‹¬ ê°œë… ìš”ì•½
-----------

| ìš©ì–´                | ì„¤ëª…                                                          |
| ------------------- | ------------------------------------------------------------- |
| **filter()**        | ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ìš”ì†Œë§Œ ë‚¨ê¸°ëŠ” ì—°ì‚°                            |
| **map()**           | ê° ìš”ì†Œì— ëŒ€í•´ ë³€í™˜ì„ ì ìš©í•˜ëŠ” ì—°ì‚°                           |
| **flatMap()**       | 1:N ë§¤í•‘ì´ ê°€ëŠ¥í•œ map + filter ì¡°í•©í˜• ì—°ì‚°                    |
| **mapPartitions()** | íŒŒí‹°ì…˜ ë‹¨ìœ„ë¡œ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ê³ ì„±ëŠ¥ ì—°ì‚°                   |
| **collect()**       | ì „ì²´ ë°ì´í„°ë¥¼ ë“œë¼ì´ë²„ë¡œ ìˆ˜ì§‘ (ì£¼ì˜: ë©”ëª¨ë¦¬ ì´ˆê³¼ ê°€ëŠ¥ì„± ìˆìŒ) |

* * *

âœ… ì‹¤ìŠµì„ í†µí•´ ë°°ìš´ ì 
-------------

*   **ê°™ì€ ì‘ì—…ì´ë¼ë„ ì—°ì‚° ë°©ì‹ì— ë”°ë¼ ì„±ëŠ¥ ì°¨ì´**ê°€ í¬ê²Œ ë°œìƒí•¨.
    
*   `mapPartitions`ëŠ” ê°€ì¥ ìµœì í™”ëœ ë°©ë²•ì´ë‚˜, **ì½”ë“œ ê°€ë…ì„±**ê³¼ **ì•ˆì •ì„±**ì„ ê³ ë ¤í•´ì•¼ í•¨.
    
*   ë°ì´í„° ê·œëª¨ê°€ í´ìˆ˜ë¡ `flatMap`, `mapPartitions`ì˜ íš¨ê³¼ê°€ ëšœë ·í•¨.
    
*   ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•´ì„ , **ì—°ì‚° ìµœì†Œí™”**ì™€ **í•¨ìˆ˜ í˜¸ì¶œ ì¤„ì´ê¸°**ê°€ í•µì‹¬ì´ë‹¤.
    