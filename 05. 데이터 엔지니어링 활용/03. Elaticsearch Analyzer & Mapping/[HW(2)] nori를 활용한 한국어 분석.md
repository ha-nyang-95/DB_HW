# nori를 활용한 한국어 분석

📘 1. 실습 주제 개요
--------------

### 🧩 주제: Nori 기반 한국어 형태소 분석기 적용 및 색인/검색 실습

<br>

### 🔍 왜 배우는가?

Elasticsearch는 기본적으로 **영어 중심의 분석기(analyzer)** 를 제공합니다. 하지만 한국어처럼 **형태소 단위로 의미가 나뉘는 언어**는 단순 띄어쓰기 기반 분석으로는 정확한 검색이 어렵습니다.

예를 들어 `"검색 기능"`이라는 문장을 일반 분석기로 처리하면 `"기능"`이라는 단어로는 검색되지 않거나 정확도가 낮아질 수 있습니다.

이를 해결하기 위해 Elasticsearch에서는 **한국어 전용 형태소 분석기인 Nori**를 제공합니다. Nori는 **어절을 형태소 단위로 분리**하고, **불용어 필터링, 품사 기반 토큰 필터링 등** 한국어에 특화된 기능을 포함하고 있어 검색 정확도를 크게 향상시킵니다.

<br>

### 🎯 학습 목표

이번 실습을 통해 다음과 같은 기술적 개념과 실습 경험을 익힙니다:

1.  **Elasticsearch 클러스터에서 Nori 플러그인 설치 여부 확인**
    
2.  **Nori 기반 사용자 정의 분석기(custom analyzer)** 구성
    
3.  **한국어 문장 색인 및 형태소 분석 적용**
    
4.  **match\_phrase 쿼리를 통한 정확한 키워드 검색 실습**
    
5.  **형태소 분석기의 실질적인 효과 확인**
    

<br>

### 🧠 비유를 통한 이해

> 영어는 단어가 끊어져 있기에 단어 단위 분석이 잘 맞습니다.  
> 하지만 한국어는 “검색기능을제공합니다”처럼 붙어 있는 문장에서  
> “검색”만 추출하려면 문장을 **의미 단위(형태소)** 로 쪼갤 수 있어야 합니다.  
> Nori는 바로 이 역할을 해주는 **한국어 해부 도구**입니다.

<br>

### 🧪 실습을 통해 얻게 되는 효과

*   한국어 자연어 처리를 위한 **형태소 분석 개념을 체험**할 수 있습니다.
    
*   실무에서 **다국어 검색 시스템을 설계할 때 필수적인 분석기 선택**에 대한 이해를 갖추게 됩니다.
    
*   검색 정확도를 높이기 위한 **검색어 정규화, 사용자 정의 분석기 구성 방법**을 학습합니다.
    

<br>
<br>

🛠️ 2. 코드 구조 및 흐름 해설 + 실행 결과 예시
-------------------------------

### 🔄 전체 흐름 요약

이번 코드는 **Elasticsearch에서 한국어 문장을 분석 및 검색**하기 위해 다음과 같은 단계로 구성되어 있습니다:

1.  클러스터 연결 및 Nori 플러그인 설치 여부 확인
    
2.  기존 인덱스 삭제
    
3.  사용자 정의 Nori 분석기 설정 및 인덱스 생성
    
4.  한국어 문장 색인
    
5.  `match_phrase` 검색 쿼리 실행 및 결과 확인
    

<br>

### 💡 단계별 상세 해설

#### ✅ 1단계: Elasticsearch 클러스터 연결

```python
es = Elasticsearch("http://localhost:9200")
```

*   Elasticsearch 인스턴스에 연결합니다.
    
*   기본적으로 `localhost`에서 실행 중인 단일 노드 클러스터를 가정합니다.
    

<br>

#### ✅ 2단계: Nori 플러그인 설치 여부 확인

```python
node_info = es.nodes.info()
nori_installed = any(
    "analysis-nori" in plugin["name"]
    for node in node_info["nodes"].values()
    for plugin in node.get("plugins", [])
)
```

*   각 노드에 설치된 플러그인 정보를 조회하고, `analysis-nori`가 포함되어 있는지 확인합니다.
    
*   플러그인이 없을 경우 이후 분석기 생성 시 오류 발생 → 사전 필수 확인 단계입니다.
    

📌 출력 예시:

```
Nori 플러그인이 설치됨.
```

<br>

#### ✅ 3단계: 기존 인덱스 삭제

```python
if es.indices.exists(index=index_name):
    es.indices.delete(index=index_name)
```

*   동일한 이름의 인덱스가 존재할 경우 삭제 후 새로 생성합니다.
    
*   실습에서 인덱스 설정 변경은 삭제 후 재생성이 일반적입니다.
    

<br>

#### ✅ 4단계: Nori 분석기 적용 인덱스 생성

```python
"settings": {
    "analysis": {
        "tokenizer": {
            "nori_user_dict": {
                "type": "nori_tokenizer",
                "decompound_mode": "mixed"
            }
        },
        "analyzer": {
            "korean_nori_analyzer": {
                "type": "custom",
                "tokenizer": "nori_tokenizer",
                "filter": ["nori_part_of_speech"]
            }
        }
    }
},
"mappings": {
    "properties": {
        "text": {
            "type": "text",
            "analyzer": "korean_nori_analyzer"
        }
    }
}
```

*   `nori_tokenizer`와 품사 필터(`nori_part_of_speech`)를 사용한 사용자 정의 분석기 생성
    
*   색인될 필드 `"text"`에 대해 이 분석기를 적용함으로써 한국어 형태소 기반 색인이 가능해집니다.
    

📌 주요 옵션:

| 설정                  | 설명                                                 |
| --------------------- | ---------------------------------------------------- |
| `decompound_mode`     | 복합어 분리 방식 (`mixed`: 원형+복합어 모두 보존)    |
| `nori_part_of_speech` | 품사 기반 불필요한 단어 필터링 (예: 조사, 접속사 등) |

<br>

#### ✅ 5단계: 한국어 문장 색인

```python
docs = [
    {"text": "엘라스틱서치는 검색 기능을 제공합니다."},
    {"text": "한국어 형태소 분석을 위해 Nori를 활용할 수 있습니다."}
]
```

*   두 개의 문서를 색인합니다. `"text"` 필드에 한국어 문장을 입력하고, 분석기 설정이 적용됩니다.
    

📌 색인 예시:

```
문서 색인 완료
```

<br>

#### ✅ 6단계: 검색 테스트 (match\_phrase)

```python
"query": {
    "match_phrase": {
        "text": "검색 기능"
    }
}
```

*   형태소 분석된 결과 중 **“검색”과 “기능”이 나란히 등장한 문장만** 검색
    
*   일반적인 `match` 쿼리와 달리, `match_phrase`는 단어 순서와 인접성을 고려합니다.
    

📌 결과 예시:

```
ID: ... , Score: 0.94, Text: 엘라스틱서치는 검색 기능을 제공합니다.
```

<br>

### 🎯 핵심 확인 포인트

*   분석기를 적용하지 않고 색인했다면 `"검색 기능"`으로 검색해도 `"엘라스틱서치는 검색 기능을 제공합니다"` 같은 문장은 검색되지 않을 수 있습니다.
    
*   Nori 분석기를 적용함으로써 문장이 **형태소 단위로 분석**되고, **보다 정확한 검색이 가능**해집니다.
    

<br>
<br>

⚙️ 3. 전체 코드 + 상세 주석
-------------------

```python
from elasticsearch import Elasticsearch
from elasticsearch.exceptions import NotFoundError
import time
import json

# ----------------------------------------------
# 1. Elasticsearch 클라이언트 연결
# ----------------------------------------------
# 로컬에서 실행 중인 Elasticsearch 인스턴스에 연결
es = Elasticsearch("http://localhost:9200")
index_name = "korean_nori"  # 생성할 인덱스 이름

# ----------------------------------------------
# 2. Nori 플러그인 설치 여부 확인
# ----------------------------------------------
print("Nori 플러그인 설치 여부 확인")

# 클러스터의 노드 정보를 조회하여 각 노드의 플러그인 목록 확인
node_info = es.nodes.info()
nori_installed = any(
    "analysis-nori" in plugin["name"]
    for node in node_info["nodes"].values()
    for plugin in node.get("plugins", [])
)

# 설치 여부에 따라 실행 여부 결정
if not nori_installed:
    print("Nori 플러그인이 설치되지 않음. 설치 후 다시 실행하세요.")
    exit(1)
else:
    print("Nori 플러그인이 설치됨.\n")

time.sleep(2)

# ----------------------------------------------
# 3. 기존 인덱스 삭제
# ----------------------------------------------
print("기존 인덱스 확인 및 삭제")

# 인덱스가 이미 존재하면 삭제 (설정 변경을 위해 사전 정리)
if es.indices.exists(index=index_name):
    es.indices.delete(index=index_name)
    print(f"기존 인덱스 [{index_name}] 삭제 완료!\n")
else:
    print(f"기존 인덱스 [{index_name}] 없음, 새로 생성 진행.\n")

time.sleep(2)

# ----------------------------------------------
# 4. Nori 분석기 적용 인덱스 생성
# ----------------------------------------------
print(f"Nori 분석기를 적용한 인덱스 [{index_name}] 생성")

# 사용자 정의 분석기를 포함한 인덱스 설정 및 매핑 구성
es.indices.create(index=index_name, body={
    "settings": {
        "analysis": {
            "tokenizer": {
                # 사용자 정의 토크나이저 설정 가능 (기본 nori_tokenizer 사용 가능)
                "nori_user_dict": {
                    "type": "nori_tokenizer",
                    "decompound_mode": "mixed"  # 복합어를 쪼개되 원형도 함께 보존
                }
            },
            "analyzer": {
                "korean_nori_analyzer": {
                    "type": "custom",
                    "tokenizer": "nori_tokenizer",  # 사용자 정의 아닌 기본 토크나이저 사용
                    "filter": ["nori_part_of_speech"]  # 품사 기반 필터링
                }
            }
        }
    },
    "mappings": {
        "properties": {
            "text": {
                "type": "text",
                "analyzer": "korean_nori_analyzer"  # 색인 시 사용할 분석기 지정
            }
        }
    }
})

print("인덱스 생성 완료\n")
time.sleep(2)

# ----------------------------------------------
# 5. 문서 색인 (한국어 문장)
# ----------------------------------------------
print("한국어 문장 색인")

# 색인할 문장 2개 정의
docs = [
    {"text": "엘라스틱서치는 검색 기능을 제공합니다."},
    {"text": "한국어 형태소 분석을 위해 Nori를 활용할 수 있습니다."}
]

# 문서 삽입 (색인)
for i, doc in enumerate(docs, start=1):
    es.index(index=index_name, doc_type="text", body=doc)  # `doc_type`은 7.x 이후 deprecated
print("문서 색인 완료\n")
time.sleep(2)

# ----------------------------------------------
# 6. 검색 테스트 (match_phrase)
# ----------------------------------------------
print("Nori를 활용한 검색 테스트")

# 형태소 분석된 결과 내에서 '검색 기능'이라는 구문이 인접하여 등장하는 문장을 검색
query = {
    "query": {
        "match_phrase": {
            "text": "검색 기능"
        }
    }
}

# 검색 실행
result = es.search(index=index_name, body=query)

# 결과 출력
for hit in result["hits"]["hits"]:
    print(f"ID: {hit['_id']}, Score: {hit['_score']}, Text: {hit['_source']['text']}")

print("\nNori 기반 한국어 분석 작업 완료!")
```

<br>
<br>

📚 4. 추가 설명 및 실무 팁
------------------

### 💡 Nori 분석기 사용 시 자주 하는 실수

| 실수/이슈                                  | 설명                                                                                                                                                    |
| ------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------- |
| ❌ Nori 플러그인 설치 없이 분석기 설정      | Nori는 기본 내장 분석기가 아니라 `analysis-nori` 플러그인을 따로 설치해야 작동합니다. 설치하지 않고 인덱스를 생성하려고 하면 400 오류가 발생합니다.     |
| ❌ `doc_type` 사용                          | Elasticsearch 7.x 이상에서는 `doc_type`이 deprecated 되었고, 8.x에서는 완전히 제거되었습니다. 가능하면 사용하지 않도록 합니다.                          |
| ❌ `match_phrase`와 `match` 혼용            | `match`는 분석된 단어 중 하나만 일치해도 검색되지만, `match_phrase`는 **순서와 연속성**을 모두 만족해야 검색됩니다. 결과 차이를 반드시 확인해야 합니다. |
| ❌ 사용자 정의 분석기 없이 검색 정확도 판단 | 기본 분석기로 한국어 문서를 색인하면 조사, 어미, 접속사 등이 함께 저장되어 검색 정확도가 매우 낮아집니다. 사용자 정의 분석기를 꼭 구성해야 합니다.      |

<br>

### 🧰 실무 활용 팁

#### 🔍 실제 서비스에서의 활용 예시

*   **전자상거래**: 고객이 “무선 이어폰”이라고 검색했을 때 “무선이어폰”, “블루투스 이어폰” 등의 제품이 노출되려면 형태소 분석이 필수입니다.
    
*   **고객 응대 시스템**: 고객 문의 내용을 분석하여 의도(Intent) 분류나 키워드 기반 대응 시 한국어 처리가 반드시 필요합니다.
    
*   **뉴스, 블로그 검색엔진**: 기사 제목과 본문 색인 시 단어 단위로는 놓치는 정보가 많기 때문에 Nori로 품사 기반 필터링이 중요합니다.
    

<br>

### 🧱 심화 학습 방향

#### 1\. 사용자 사전(User Dictionary) 활용

*   고유명사(예: “삼성전자”, “이재용”)가 분리되는 문제를 해결하기 위해 사용자 사전을 직접 지정할 수 있습니다.
    
*   사전은 텍스트 파일로 제공하며, Elasticsearch 설정 경로에 등록해야 합니다.
    

#### 2\. `decompound_mode` 실험

| 모드      | 설명                                    |
| --------- | --------------------------------------- |
| `none`    | 복합어를 분리하지 않음                  |
| `discard` | 복합어만 유지, 구성어는 제거            |
| `mixed`   | 복합어와 구성어 모두 유지 (가장 유연함) |

→ 예를 들어 `"데이터분석"`이라는 단어를 `mixed`로 처리하면 `"데이터"`, `"분석"`, `"데이터분석"` 모두 색인됩니다.

#### 3\. 품사 기반 필터링 튜닝

*   `nori_part_of_speech`를 사용하면 불필요한 조사, 감탄사, 접속사 등을 제거할 수 있습니다.
    
*   원하는 품사만 남기거나, 특정 품사만 제거하도록 필터 설정을 튜닝할 수 있습니다.
    

<br>

### 🧠 마무리 정리

이번 실습은 단순한 Elasticsearch 사용을 넘어서, **한국어 자연어 처리를 검색 시스템에 실제로 적용하는 방법**을 다루었습니다.  
Nori 분석기를 설정하고 색인 및 검색을 실험함으로써, **형태소 분석의 중요성**, **검색 정확도 향상 전략**, **Elasticsearch 설정 커스터마이징**까지 경험할 수 있었습니다.

실무에서 한국어 기반 검색 서비스를 설계하거나, 다국어를 지원하는 플랫폼을 만들 때 반드시 알아야 할 핵심 역량입니다.  
단순한 설정을 넘어, **어떤 데이터에 어떤 분석기를 적용할지 판단하는 능력**이 진짜 실무 감각이 될 것입니다.
