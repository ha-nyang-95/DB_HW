{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) # FutureWarning ì œê±°\n",
    "warnings.filterwarnings(\"ignore\", message=\"Could not find the number of physical cores\")\n",
    "\n",
    "# ! pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "# plt.rcParams['font.family'] ='Malgun Gothic'\n",
    "plt.rcParams['font.family'] ='AppleGothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "file_path = pd.read_csv('data/group_data.csv')\n",
    "data = file_path.copy()\n",
    "data\n",
    "\n",
    "# íŠ¹ì • ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ë°ì´í„° í•„í„°ë§\n",
    "# andê°€ ì•„ë‹Œ & ì‚¬ìš©! ê´„í˜¸ ê¼­ í•„ìš”!\n",
    "filtered_data = data.loc[(data['value'] >= 10 ) & (data['value'] <= 20 )]  # (íŒíŠ¸: 10~20 ì‚¬ì´ í•„í„°ë§)\n",
    "print(f'ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ì˜ ê°œìˆ˜: {len(filtered_data)}')  # (íŒíŠ¸: ì¡°ê±´ì— ë§ëŠ” ë°ì´í„° ê°œìˆ˜ ì¶œë ¥)\n",
    "filtered_data.head()\n",
    "\n",
    "# ê·¸ë£¹í™” í›„ í‰ê·  ê³„ì‚°\n",
    "grouped_mean = filtered_data.groupby('category')['value'].mean()  # (íŒíŠ¸: categoryë³„ ê·¸ë£¹í™” -> í‰ê· )\n",
    "grouped_mean\n",
    "\n",
    "# ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬\n",
    "sorted_grouped_mean = grouped_mean.sort_values(ascending=False)  # (íŒíŠ¸: ë‚´ë¦¼ì°¨ìˆœ â†’ False)\n",
    "sorted_grouped_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind   # (íŒíŠ¸: ë‘ ì§‘ë‹¨ í‰ê·  ë¹„êµìš© t-test í•¨ìˆ˜)\n",
    "\n",
    "# 2. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df_ts = pd.read_csv('data/time_series_data.csv')  # (íŒíŠ¸: ìƒëŒ€ ê²½ë¡œ ì‚¬ìš©)\n",
    "df_ts\n",
    "df_ts.dtypes\n",
    "\n",
    "# 3. ë‚ ì§œ ë°ì´í„° í˜•ì‹ ë³€í™˜\n",
    "df_ts[\"Date\"] = pd.to_datetime(df_ts[\"Date\"])  # (íŒíŠ¸: ë¬¸ìì—´ â†’ datetime)\n",
    "df_ts.dtypes\n",
    "\n",
    "# 4. ë‚ ì§œ ê¸°ì¤€ ì •ë ¬\n",
    "df_ts = df_ts.sort_values(by='Date')  # (íŒíŠ¸: ë‚ ì§œ ìˆœ ì •ë ¬)\n",
    "df_ts\n",
    "\n",
    "# 5. ê¸°ë³¸ í†µê³„ëŸ‰\n",
    "summary_stats = df_ts[['value']].describe()  # (íŒíŠ¸: 'value' ì—´ë§Œ í†µê³„ ë³´ê¸°)\n",
    "\n",
    "# 6. í†µê³„ëŸ‰ ì¶œë ¥\n",
    "print(\"ì „ì²´ ë°ì´í„°ì˜ ê¸°ë³¸ í†µê³„ëŸ‰\")\n",
    "summary_stats\n",
    "\n",
    "# 7. ì›” ì •ë³´ ì¶”ì¶œ\n",
    "df_ts[\"Month\"] = df_ts[\"Date\"].dt.month   # (íŒíŠ¸: ë‚ ì§œ â†’ ì›” ì¶”ì¶œ)\n",
    "df_ts\n",
    "\n",
    "# 8. 1ì›”ê³¼ 12ì›” ë°ì´í„° ì„ íƒ\n",
    "jan_values = df_ts[df_ts[\"Month\"] == 1 ][\"value\"]  # (íŒíŠ¸: 1ì›”)\n",
    "dec_values = df_ts[df_ts[\"Month\"] == 12 ][\"value\"]  # (íŒíŠ¸: 12ì›”)\n",
    "\n",
    "# 9. í‰ê·  ê³„ì‚°\n",
    "jan_mean = jan_values.mean()\n",
    "dec_mean = dec_values.mean()\n",
    "\n",
    "# 10. í‰ê·  ì¶œë ¥\n",
    "print(\"\\n1ì›”ê³¼ 12ì›”ì˜ í‰ê·  ë¹„êµ\")\n",
    "print(f\"1ì›” í‰ê· : {jan_mean:.2f}\")\n",
    "print(f\"12ì›” í‰ê· : {dec_mean:.2f}\")\n",
    "\n",
    "# 11. ë…ë¦½í‘œë³¸ t-ê²€ì •\n",
    "t_stat, p_value = ttest_ind(jan_values, dec_values, equal_var = False)  # (íŒíŠ¸: ë¶„ì‚° ë‹¤ë¦„ ê°€ì •)\n",
    "\n",
    "# 12. t-ê²€ì • ê²°ê³¼ ì¶œë ¥\n",
    "print(\"\\në…ë¦½í‘œë³¸ t-ê²€ì • ê²°ê³¼\")\n",
    "print(f\"t-ê°’: {t_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "# 13. ê²°ê³¼ í•´ì„\n",
    "if p_value < 0.05 :   # (íŒíŠ¸: ìœ ì˜ìˆ˜ì¤€ 0.05)\n",
    "    print(\"1ì›”ê³¼ 12ì›”ì˜ ê°’ì´ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤!\")\n",
    "else:\n",
    "    print(\"1ì›”ê³¼ 12ì›”ì˜ ê°’ì— í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"ì—°ì´ˆì™€ ì—°ë§ì˜ ê°’ì´ ë¹„ìŠ·í•œ íŒ¨í„´ì„ ë³´ì…ë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# ws_3_1 - ì •ê·œë¶„í¬ ê¸°ì´ˆ ë¶„ì„\n",
    "# ================================\n",
    "\n",
    "mu, sigma, size = 50, 10, 1000\n",
    "# Q1: ì •ê·œë¶„í¬ ë°ì´í„°ë¥¼ ìƒì„±í•˜ì„¸ìš”.\n",
    "data = np.random.normal(mu, sigma, size)  # (íŒíŠ¸: í‰ê· , í‘œì¤€í¸ì°¨, ê°œìˆ˜)\n",
    "data\n",
    "\n",
    "# Q2: ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”.\n",
    "df = pd.DataFrame({\"value\": data})  # (íŒíŠ¸: 'value' ì»¬ëŸ¼ìœ¼ë¡œ ì €ì¥)\n",
    "df\n",
    "\n",
    "# Q3: ì „ì²´ í†µê³„ëŸ‰ì„ ì¶œë ¥í•˜ì„¸ìš”.\n",
    "summary_stats = df[\"value\"].describe()  # (íŒíŠ¸: í‰ê· , í‘œì¤€í¸ì°¨, ì‚¬ë¶„ìœ„ ë“± ìš”ì•½ í†µê³„)\n",
    "summary_stats\n",
    "\n",
    "# Q4: í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ê³„ì‚°\n",
    "mean_value = df[\"value\"].mean()  # (íŒíŠ¸: í‰ê· )\n",
    "std_value = df[\"value\"].std()  # (íŒíŠ¸: í‘œì¤€í¸ì°¨)\n",
    "\n",
    "# Q5: 68-95-99.7 ë²•ì¹™ ì ìš©\n",
    "within_1_sigma = np.sum((df[\"value\"] >= mu - sigma) & (df[\"value\"] <= mu + sigma)) / size * 100\n",
    "within_2_sigma = np.sum((df[\"value\"] >= mu - 2*sigma) & (df[\"value\"] <= mu + 2*sigma)) / size * 100\n",
    "within_3_sigma = np.sum((df[\"value\"] >= mu - 3*sigma) & (df[\"value\"] <= mu + 3*sigma)) / size * 100\n",
    "\n",
    "print(within_1_sigma)\n",
    "print(within_2_sigma)\n",
    "print(within_3_sigma)\n",
    "\n",
    "# Q6: í™•ë¥ ë°€ë„í•¨ìˆ˜(PDF) ê³„ì‚°\n",
    "sample_value = mu  # (íŒíŠ¸: í‰ê·  ìœ„ì¹˜ì—ì„œì˜ ë°€ë„)\n",
    "pdf_value = norm.pdf(sample_value, loc=mu, scale=sigma)  # (íŒíŠ¸: í‰ê· , í‘œì¤€í¸ì°¨)\n",
    "print(pdf_value)\n",
    "\n",
    "# Q7: xì¶• ë²”ìœ„ ì„¤ì • ë° PDF ì‹œê°í™”\n",
    "x = np.linspace(mu - 4*sigma, mu + 4*sigma, 1000)\n",
    "pdf = norm.pdf(x, loc=mu, scale=sigma)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, pdf, label='ì •ê·œë¶„í¬ PDF', color='blue')\n",
    "plt.axvline(mu, color='red', linestyle='--', label=f'í‰ê·  (mu = {mu})')\n",
    "plt.scatter(mu, pdf_value, color='red', zorder=5)\n",
    "plt.text(mu + 1, pdf_value, f'{pdf_value:.5f}', color='red', fontsize=12)\n",
    "\n",
    "plt.title('ì •ê·œë¶„í¬ì™€ í‰ê· ì—ì„œì˜ í™•ë¥ ë°€ë„ê°’ (PDF)')\n",
    "plt.xlabel('ê°’ (x)')\n",
    "plt.ylabel('í™•ë¥ ë°€ë„ (PDF)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(\"ì „ì²´ ë°ì´í„°ì˜ ê¸°ë³¸ í†µê³„ëŸ‰\")\n",
    "print(summary_stats)\n",
    "\n",
    "print(\"\\n68-95-99.7 ë²•ì¹™ ì ìš© ê²°ê³¼\")\n",
    "print(f\"68% ë²”ìœ„ ë‚´ ë°ì´í„° ë¹„ìœ¨: {within_1_sigma:.2f}%\")\n",
    "print(f\"95% ë²”ìœ„ ë‚´ ë°ì´í„° ë¹„ìœ¨: {within_2_sigma:.2f}%\")\n",
    "print(f\"99.7% ë²”ìœ„ ë‚´ ë°ì´í„° ë¹„ìœ¨: {within_3_sigma:.2f}%\")\n",
    "\n",
    "print(\"\\nì •ê·œë¶„í¬ ê²€ì • ê²°ê³¼\")\n",
    "print(f\"ìƒ˜í”Œ í‰ê· : {mean_value:.2f}, ìƒ˜í”Œ í‘œì¤€í¸ì°¨: {std_value:.2f}\")\n",
    "print(f\"ì´ë¡ ì  ì •ê·œë¶„í¬ì˜ í‰ê· : {mu}, í‘œì¤€í¸ì°¨: {sigma}\")\n",
    "print(f\"í‰ê·  ê°’({sample_value})ì—ì„œì˜ ì´ë¡ ì  í™•ë¥ ë°€ë„í•¨ìˆ˜(PDF) ê°’: {pdf_value:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# ws_3_2 - ì¡°ê±´ í•„í„°ë§ ë° ìƒê´€ê³„ìˆ˜\n",
    "# ================================\n",
    "\n",
    "# Q8: CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "file_path = \"data/sample_data.csv\"\n",
    "df = pd.read_csv(file_path)  # (íŒíŠ¸: ë³€ìˆ˜ file_path ì‚¬ìš©)\n",
    "df\n",
    "\n",
    "# Q9: ë°ì´í„° ì •ë³´ í™•ì¸\n",
    "df.info()  # (íŒíŠ¸: info í•¨ìˆ˜)\n",
    "\n",
    "# Q10: ê¸°ë³¸ í†µê³„ëŸ‰ í™•ì¸\n",
    "summary_stats = df.describe()  # (íŒíŠ¸: describe í•¨ìˆ˜)\n",
    "summary_stats\n",
    "\n",
    "# Q11: column_nameì´ 50 ì´ìƒì¸ ë°ì´í„° í•„í„°ë§\n",
    "filtered_df = df[df[\"column_name\"] >= 50]  # (íŒíŠ¸: ì´ìƒ ë˜ëŠ” ê°™ìŒ)\n",
    "filtered_df\n",
    "\n",
    "# Q12: other_column_nameì´ 0ë³´ë‹¤ í° ë°ì´í„° í•„í„°ë§\n",
    "positive_df = df[df[\"other_column_name\"] > 0]  # (íŒíŠ¸: 0 ì´ˆê³¼)\n",
    "positive_df\n",
    "\n",
    "# Q13: ë‘ ì¡°ê±´ì„ ëª¨ë‘ ë§Œì¡±í•˜ëŠ” ë°ì´í„° ì¶”ì¶œ\n",
    "filtered_combined = df[(df[\"column_name\"] >= 50) & (df[\"other_column_name\"] > 0)]  # (íŒíŠ¸: ë…¼ë¦¬ ì—°ì‚°ì)\n",
    "filtered_combined\n",
    "\n",
    "# Q14: ìƒê´€ê³„ìˆ˜ ê³„ì‚°\n",
    "correlation = df[[\"column_name\", \"other_column_name\"]].corr()  # (íŒíŠ¸: ìƒê´€ê³„ìˆ˜ í•¨ìˆ˜)\n",
    "correlation\n",
    "\n",
    "# Q15: ê²°ê³¼ ì¶œë ¥\n",
    "print(\"ğŸ“Š ë°ì´í„° ì •ë³´:\")\n",
    "print(df.info())  # (íŒíŠ¸: info í•¨ìˆ˜ í˜¸ì¶œ)\n",
    "\n",
    "print(\"\\nğŸ“Š ì „ì²´ ë°ì´í„°ì˜ ê¸°ë³¸ í†µê³„ëŸ‰:\")\n",
    "print(summary_stats)\n",
    "\n",
    "print(\"\\nğŸ“Š column_nameì´ 50 ì´ìƒì¸ ë°ì´í„° ê°œìˆ˜:\", len(filtered_df))  # (íŒíŠ¸: í–‰ ê°œìˆ˜)\n",
    "print(\"\\nğŸ“Š other_column_nameì´ 0ë³´ë‹¤ í° ë°ì´í„° ê°œìˆ˜:\", len(positive_df))\n",
    "print(\"\\nğŸ“Š ë‘ ê°œì˜ ì¡°ê±´(column_name >= 50 & other_column_name > 0)ì„ ë§Œì¡±í•˜ëŠ” ë°ì´í„° ê°œìˆ˜:\", len(filtered_combined))\n",
    "\n",
    "print(\"\\nğŸ“Š ì»¬ëŸ¼ ê°„ ìƒê´€ê³„ìˆ˜:\")\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# ws_3_3 - ë°•ìŠ¤í”Œë¡¯ í†µê³„ ë° ì´ìƒì¹˜ íƒì§€\n",
    "# ================================\n",
    "\n",
    "# Q16: ë°ì´í„°í”„ë ˆì„ì—ì„œ ì»¬ëŸ¼ë³„ ì œ1ì‚¬ë¶„ìœ„ìˆ˜ë¥¼ êµ¬í•˜ì„¸ìš”.\n",
    "Q1 = df[column].quantile(0.25)  # (íŒíŠ¸: quantile ì‚¬ìš©)\n",
    "\n",
    "# Q17: ì¤‘ì•™ê°’ì„ êµ¬í•˜ì„¸ìš”.\n",
    "Q2 = df[column].median()  # (íŒíŠ¸: ì¤‘ì•™ê°’)\n",
    "\n",
    "# Q18: ì œ3ì‚¬ë¶„ìœ„ìˆ˜ë¥¼ êµ¬í•˜ì„¸ìš”.\n",
    "Q3 = df[column].quantile(0.75)  # (íŒíŠ¸: quantile ì‚¬ìš©)\n",
    "\n",
    "# Q19: IQR ê³„ì‚°\n",
    "IQR = Q3 - Q1  # (íŒíŠ¸: Q1ì„ ë¹¼ì•¼ í•¨)\n",
    "\n",
    "# Q20: ì¼ë°˜ ì´ìƒì¹˜ ê¸°ì¤€ í•˜í•œ/ìƒí•œ ê³„ì‚°\n",
    "lower_bound_1_5 = Q1 - 1.5 * IQR  # (íŒíŠ¸: 1.5)\n",
    "upper_bound_1_5 = Q3 + 1.5 * IQR\n",
    "\n",
    "# Q21: ì´ìƒì¹˜ í•„í„°ë§\n",
    "mild_outliers = df[(df[column] < lower_bound_1_5) | (df[column] > upper_bound_1_5)]  # (íŒíŠ¸: ì¡°ê±´ í•„í„°ë§)\n",
    "\n",
    "# Q22: ë¶„ì‚°ê³¼ í‘œì¤€í¸ì°¨ êµ¬í•˜ê¸°\n",
    "variance = np.var(df[column])\n",
    "std_dev = np.std(df[column])  # (íŒíŠ¸: í‘œì¤€í¸ì°¨ í•¨ìˆ˜)\n",
    "\n",
    "# Q23: í‰ê·  ì ˆëŒ€ í¸ì°¨(MAD) ê³„ì‚°\n",
    "mad = np.mean(np.abs(df[column] - df[column].median()))  # (íŒíŠ¸: ì¤‘ì•™ê°’ ê¸°ì¤€ ì˜¤ì°¨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# ws_3_4 - ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ë° íŒŒìƒ ë³€ìˆ˜ ìƒì„±\n",
    "# ================================\n",
    "\n",
    "# Q24: ê²°ì¸¡ì¹˜ í™•ì¸\n",
    "missing_values = df.isna().sum( )  # (íŒíŠ¸: isnull + sum)\n",
    "\n",
    "# Q25: ì¤‘ì•™ê°’ìœ¼ë¡œ ê²°ì¸¡ì¹˜ ëŒ€ì²´\n",
    "df['column_with_missing'] = df['column_with_missing'].fillna(df['column_with_missing'].median())  # (íŒíŠ¸: fillna + median)\n",
    "\n",
    "# Q26: column_1ê³¼ column_2ì˜ í‰ê· ì„ êµ¬í•˜ëŠ” íŒŒìƒ ë³€ìˆ˜ ìƒì„±\n",
    "df['column_mean'] = (df['column_1'] + df['column_2']) / 2  # (íŒíŠ¸: ì‚°ìˆ  í‰ê· )\n",
    "\n",
    "# Q27: column_3ì´ ì§ìˆ˜ì¸ì§€ ì—¬ë¶€ë¥¼ íŒë³„í•˜ëŠ” íŒŒìƒ ë³€ìˆ˜ ìƒì„±\n",
    "df['is_even'] = df['column_3'] % 2 == 0  # (íŒíŠ¸: ì§ìˆ˜ëŠ” 2ë¡œ ë‚˜ëˆ  ë‚˜ë¨¸ì§€ê°€ 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# ws_3_5 - ì‹œê³„ì—´ ë°ì´í„° ì „ì²˜ë¦¬ ë° ì‹œê°í™”\n",
    "# ================================\n",
    "\n",
    "# Q28: ë¬¸ìì—´ì„ datetime í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "df['Date'] = pd.to_datetime(df['Date'])  # (íŒíŠ¸: ë‚ ì§œí˜• ë³€í™˜)\n",
    "\n",
    "# Q29: í‰ê· ê°’ìœ¼ë¡œ ê²°ì¸¡ì¹˜ ëŒ€ì²´\n",
    "df = df.fillna(df.mean())  # (íŒíŠ¸: fillna + mean)\n",
    "\n",
    "# Q30: ì´ìƒì¹˜ ì œê±° (IQR ê¸°ì¤€)\n",
    "Q1 = df[col].quantile(0.25)\n",
    "Q3 = df[col].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]  # (íŒíŠ¸: ì´ìƒì¹˜ ì œê±° ì¡°ê±´ì‹)\n",
    "\n",
    "# Q31: ìƒê´€ê³„ìˆ˜ í–‰ë ¬ ê³„ì‚°\n",
    "correlation_matrix = df.corr()  # (íŒíŠ¸: corr)\n",
    "\n",
    "# Q32: íˆíŠ¸ë§µ ì‹œê°í™”\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "\n",
    "# Q33: pairplot ê·¸ë¦¬ê¸°\n",
    "sns.pairplot(df.drop(columns=['Date']), kind='reg', diag_kind='kde')  # (íŒíŠ¸: íšŒê·€ì„  í¬í•¨, ë¶„í¬ëŠ” KDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
