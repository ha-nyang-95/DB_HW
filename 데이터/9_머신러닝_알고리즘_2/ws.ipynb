{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) # FutureWarning 제거\n",
    "warnings.filterwarnings(\"ignore\", message=\"Could not find the number of physical cores\")\n",
    "\n",
    "# ! pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "# plt.rcParams['font.family'] ='Malgun Gothic'\n",
    "plt.rcParams['font.family'] ='AppleGothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ws_9_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 정확도: 0.78\n",
      "분류 리포트:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.71      0.83         7\n",
      "           1       0.50      1.00      0.67         2\n",
      "\n",
      "    accuracy                           0.78         9\n",
      "   macro avg       0.75      0.86      0.75         9\n",
      "weighted avg       0.89      0.78      0.80         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 1. 교통량 데이터 로드\n",
    "# 예시 파일 경로를 사용하여 엑셀 데이터를 불러옵니다.\n",
    "weekdays_data = pd.read_excel('data/weekday_traffic.xlsx')\n",
    "\n",
    "# 2. 독립 변수: 각 날의 8시, 9시, 10시 교통량 데이터를 사용\n",
    "# '8시', '9시', '10시' 열을 독립 변수로 선택하여 교통량 변수를 구성합니다.\n",
    "X = weekdays_data.loc[:, ['8시', '9시', '10시']].values\n",
    "\n",
    "# 3. 종속 변수: 혼잡 여부 (True/False -> 1/0 변환)\n",
    "# '혼잡' 열을 종속 변수로 사용하며, 이 값이 True이면 1, False이면 0으로 변환합니다.\n",
    "y = weekdays_data['혼잡'].astype(int).values\n",
    "\n",
    "# 4. 데이터 분리 (훈련 데이터 80%, 테스트 데이터 20%)\n",
    "# SVM 모델 학습을 위해 train_test_split을 사용해 데이터를 분리합니다.\n",
    "# 참고: Scikit-learn - train_test_split: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "# 5. 데이터 스케일링 (SVM 성능 향상을 위해 표준화)\n",
    "# SVM 모델은 특성의 스케일에 민감하므로 StandardScaler를 사용해 데이터를 표준화합니다.\n",
    "# 참고: Scikit-learn - StandardScaler: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 6. SVM 모델 생성 및 학습 (훈련 데이터로 학습)\n",
    "# SVM 모델을 생성하여 학습합니다. 여기서는 선형 커널을 사용합니다.\n",
    "# 참고: Scikit-learn - SVC: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "model = SVC(kernel='linear',random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 7. 테스트 데이터로 예측 수행\n",
    "# 학습된 모델을 사용해 테스트 데이터에 대한 혼잡 여부를 예측합니다.\n",
    "# 참고: Scikit-learn - predict 함수: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC.predict\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# 8. 예측 결과 평가\n",
    "# accuracy_score와 classification_report를 사용해 모델의 정확도 및 성능을 평가합니다.\n",
    "# 참고: Scikit-learn - accuracy_score: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
    "# 참고: Scikit-learn - classification_report: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "report = classification_report(y_test,y_pred,zero_division=0)\n",
    "\n",
    "# 9. 결과 출력\n",
    "print(f\"모델 정확도: {accuracy:.2f}\")\n",
    "print(\"분류 리포트:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ws_9_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 정확도: 0.78\n",
      "분류 리포트:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.71      0.83         7\n",
      "           1       0.50      1.00      0.67         2\n",
      "\n",
      "    accuracy                           0.78         9\n",
      "   macro avg       0.75      0.86      0.75         9\n",
      "weighted avg       0.89      0.78      0.80         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 1. 교통량 데이터 로드\n",
    "# 예시 파일 경로를 사용하여 엑셀 데이터를 불러옵니다.\n",
    "weekdays_data = pd.read_excel('data/weekday_traffic.xlsx')\n",
    "\n",
    "# 2. 독립 변수: 각 날의 8시, 9시, 10시 교통량 데이터를 사용\n",
    "# '8시', '9시', '10시' 열을 독립 변수로 선택하여 교통량 변수를 구성합니다.\n",
    "X = weekdays_data.loc[:, ['8시', '9시', '10시']].values\n",
    "\n",
    "# 3. 종속 변수: 혼잡 여부 (True/False -> 1/0 변환)\n",
    "# '혼잡' 열을 종속 변수로 사용하며, 이 값이 True이면 1, False이면 0으로 변환합니다.\n",
    "y = weekdays_data['혼잡'].astype(int).values\n",
    "\n",
    "# 4. 데이터 분리 (훈련 데이터 80%, 테스트 데이터 20%)\n",
    "# SVM 모델 학습을 위해 train_test_split을 사용해 데이터를 분리합니다.\n",
    "# 참고: Scikit-learn - train_test_split: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "X_train, X_test, y_train, y_test =train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "# 5. 데이터 스케일링\n",
    "# SVM 모델은 특성의 스케일에 민감하므로 StandardScaler를 사용해 데이터를 표준화합니다.\n",
    "# 참고: Scikit-learn - StandardScaler: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 6. 비선형 SVM 모델 생성 및 학습 (RBF 커널 사용)\n",
    "# 비선형 분류 문제에 적합한 RBF 커널을 사용하여 SVM 모델을 생성하고 학습합니다.\n",
    "# 참고: Scikit-learn - SVC (Support Vector Classifier): https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "model = SVC(kernel='rbf', random_state=42)  # RBF 커널을 사용한 SVM 모델\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 7. 테스트 데이터로 예측 수행\n",
    "# 학습된 모델을 사용해 테스트 데이터를 예측합니다.\n",
    "# 참고: Scikit-learn - predict 함수: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC.predict\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# 8. 결과 평가\n",
    "# 모델의 성능을 평가하기 위해 accuracy_score와 classification_report를 사용합니다.\n",
    "# 참고: Scikit-learn - accuracy_score: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
    "# 참고: Scikit-learn - classification_report: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "report = classification_report(y_test,y_pred)\n",
    "\n",
    "# 9. 결과 출력\n",
    "print(f\"모델 정확도: {accuracy:.2f}\")\n",
    "print(\"분류 리포트:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ws_9_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 정확도: 0.56\n",
      "분류 리포트:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71         7\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.56         9\n",
      "   macro avg       0.36      0.36      0.36         9\n",
      "weighted avg       0.56      0.56      0.56         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 1. 교통량 데이터 로드\n",
    "# Pandas를 사용하여 엑셀 파일을 읽어옵니다.\n",
    "weekdays_data = pd.read_excel('data/weekday_traffic.xlsx')\n",
    "\n",
    "# 2. 독립 변수: 8시, 9시, 10시 교통량을 사용\n",
    "# 독립 변수로 '8시', '9시', '10시' 열을 선택합니다.\n",
    "X = weekdays_data.loc[:, ['8시', '9시', '10시']].values\n",
    "\n",
    "# 3. 종속 변수: 혼잡 여부 (True/False -> 1/0 변환)\n",
    "# '혼잡' 열을 사용하여 1/0으로 변환합니다.\n",
    "y = weekdays_data['혼잡'].astype(int).values\n",
    "\n",
    "# 4. 데이터 분리 (훈련 데이터 80%, 테스트 데이터 20%)\n",
    "# 데이터를 학습용과 테스트용으로 나눕니다.\n",
    "# 참고: Scikit-learn - train_test_split: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "# 5. 데이터 스케일링\n",
    "# 데이터를 표준화하여 모델 성능을 향상시킵니다.\n",
    "# 참고: Scikit-learn - StandardScaler: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 6. Gradient Boosting 모델 생성 및 학습\n",
    "# GradientBoostingClassifier를 사용하여 모델을 생성하고 학습합니다.\n",
    "# n_estimators=10, learning_rate=0.1, max_depth=3, random_state=42를 설정해 맞춰줍니다.\n",
    "# 참고: Scikit-learn - GradientBoostingClassifier: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
    "model = GradientBoostingClassifier(n_estimators=10, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 7. 테스트 데이터로 예측 수행\n",
    "# 학습된 모델로 테스트 데이터를 예측합니다.\n",
    "# 참고: Scikit-learn - predict 함수: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier.predict\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# 8. 결과 평가\n",
    "# 모델의 성능을 평가하기 위해 accuracy_score와 classification_report를 사용합니다.\n",
    "# 참고: Scikit-learn - accuracy_score: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
    "# 참고: Scikit-learn - classification_report: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "report = classification_report(y_test,y_pred)\n",
    "\n",
    "# 9. 결과 출력\n",
    "print(f\"모델 정확도: {accuracy:.2f}\")\n",
    "print(\"분류 리포트:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ws_9_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 정확도: 0.89\n",
      "분류 리포트:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92         7\n",
      "           1       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.89         9\n",
      "   macro avg       0.83      0.93      0.86         9\n",
      "weighted avg       0.93      0.89      0.90         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 1. 교통량 데이터 로드\n",
    "# Pandas를 사용하여 엑셀 파일을 읽어옵니다.\n",
    "weekdays_data = pd.read_excel('data/weekday_traffic.xlsx')\n",
    "\n",
    "# 2. 독립 변수: 8시, 9시, 10시 교통량을 사용\n",
    "# 독립 변수로 '8시', '9시', '10시' 열을 선택합니다.\n",
    "X = weekdays_data.loc[:, ['8시', '9시', '10시']].values\n",
    "\n",
    "# 3. 종속 변수: 혼잡 여부 (True/False -> 1/0 변환)\n",
    "# '혼잡' 열을 사용하여 True/False 값을 1/0으로 변환합니다.\n",
    "y = weekdays_data['혼잡'].astype(int).values\n",
    "\n",
    "# 4. 데이터 분리 (훈련 데이터 80%, 테스트 데이터 20%)\n",
    "# 데이터를 학습용과 테스트용으로 나눕니다.\n",
    "# 참고: Scikit-learn - train_test_split: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "# 5. 데이터 스케일링\n",
    "# Logistic Regression 모델에서 성능을 향상시키기 위해 데이터를 표준화합니다.\n",
    "# 참고: Scikit-learn - StandardScaler: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 6. Logistic Regression 모델 생성 (L2 정규화 적용)\n",
    "# Logistic Regression 모델을 생성하며, 기본적으로 L2 정규화(penalty='l2')가 적용됩니다.\n",
    "# L2 정규화는 모델의 복잡도를 줄이고 과적합을 방지하기 위해 사용되며, 이를 통해 가중치 값들이 너무 커지는 것을 막습니다.\n",
    "# C=1.0은 정규화 강도를 조정하는 하이퍼파라미터로, C 값이 클수록 정규화가 약해지고, 값이 작을수록 더 강한 정규화가 적용됩니다.\n",
    "# 참고: Scikit-learn - LogisticRegression: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "model = LogisticRegression()  # L2 정규화\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 7. 테스트 데이터로 예측 수행\n",
    "# 학습된 모델로 테스트 데이터를 예측합니다.\n",
    "# 참고: Scikit-learn - predict 함수: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# 8. 결과 평가\n",
    "# 모델의 성능을 평가하기 위해 accuracy_score와 classification_report를 사용합니다.\n",
    "# 참고: Scikit-learn - accuracy_score: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
    "# 참고: Scikit-learn - classification_report: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "report = classification_report(y_test,y_pred)\n",
    "\n",
    "# 9. 결과 출력\n",
    "print(f\"모델 정확도: {accuracy:.2f}\")\n",
    "print(\"분류 리포트:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ws_9_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Random Forest ====\n",
      "Accuracy: 0.78\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88         7\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.78         9\n",
      "   macro avg       0.39      0.50      0.44         9\n",
      "weighted avg       0.60      0.78      0.68         9\n",
      "\n",
      "\n",
      "==== Gradient Boosting ====\n",
      "Accuracy: 0.56\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71         7\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.56         9\n",
      "   macro avg       0.36      0.36      0.36         9\n",
      "weighted avg       0.56      0.56      0.56         9\n",
      "\n",
      "\n",
      "==== Logistic Regression ====\n",
      "Accuracy: 0.89\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92         7\n",
      "           1       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.89         9\n",
      "   macro avg       0.83      0.93      0.86         9\n",
      "weighted avg       0.93      0.89      0.90         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 1. 교통량 데이터 로드\n",
    "# Pandas를 사용하여 엑셀 파일을 읽어옵니다.\n",
    "weekdays_data = pd.read_excel('data/weekday_traffic.xlsx')\n",
    "\n",
    "# 2. 독립 변수: 8시, 9시, 10시 교통량을 사용\n",
    "# 독립 변수로 '8시', '9시', '10시' 열을 선택합니다.\n",
    "X = weekdays_data.loc[:, ['8시', '9시', '10시']].values\n",
    "\n",
    "# 3. 종속 변수: 혼잡 여부 (True/False -> 1/0 변환)\n",
    "# '혼잡' 열을 사용하여 True/False 값을 1/0으로 변환합니다.\n",
    "y = weekdays_data['혼잡'].astype(int).values\n",
    "\n",
    "# 4. 데이터 분리 (훈련 데이터 80%, 테스트 데이터 20%)\n",
    "# 데이터를 학습용과 테스트용으로 나눕니다.\n",
    "# 참고: Scikit-learn - train_test_split: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "# 5. 데이터 스케일링 (로지스틱 회귀에 반드시 필요)\n",
    "# 데이터의 스케일에 민감한 로지스틱 회귀 모델에 적용하기 때문에 표준화를 진행합니다. (상대적으로 트리 기반 모델에서는 덜 민감하다는거지 하면 안되는 것은 아닙니다.)\n",
    "# 앙상블 모델은 스케일링 없이 원본 데이터를 사용합니다.\n",
    "# 참고: Scikit-learn - StandardScaler: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 6. 앙상블 및 로지스틱 회귀 모델 설정\n",
    "\n",
    "# (1) 랜덤 포레스트 - 배깅 방식\n",
    "# 배깅(bagging) 방식의 랜덤 포레스트 모델을 생성합니다. \n",
    "# - n_estimators=10: 트리의 개수를 10개로 설정\n",
    "# - random_state=42: 결과 재현을 위해 고정된 난수 시드를 설정\n",
    "# 참고: Scikit-learn - RandomForestClassifier: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "rf_model = RandomForestClassifier(n_estimators=10,random_state=42)\n",
    "\n",
    "# (2) Gradient Boosting - 부스팅 방식\n",
    "# 부스팅 방식의 Gradient Boosting 모델을 생성합니다.\n",
    "# - n_estimators=10: 트리 개수를 10개로 설정\n",
    "# - learning_rate=0.1: 학습률을 0.1로 설정하여 학습 속도 조절\n",
    "# - max_depth=3: 각 트리의 최대 깊이를 3으로 설정하여 과적합 방지\n",
    "# 참고: Scikit-learn - GradientBoostingClassifier: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
    "gb_model = GradientBoostingClassifier(n_estimators=10,learning_rate=0.1,max_depth=3)\n",
    "\n",
    "# (3) Logistic Regression - 로지스틱 회귀 모델\n",
    "# Logistic Regression 모델을 생성하며 L2 정규화를 사용합니다.\n",
    "# - penalty='l2': L2 정규화(릿지 회귀)를 사용\n",
    "# - C=1.0: 정규화 강도 조절, C 값이 클수록 약한 정규화, 작을수록 강한 정규화\n",
    "# 참고: Scikit-learn - LogisticRegression: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "lr_model = LogisticRegression(penalty='l2',C=1.0)\n",
    "\n",
    "# 7. 모델 학습 및 성능 평가\n",
    "# 설정한 세 가지 모델에 대해 학습을 수행하고, 테스트 데이터에 대한 성능을 평가합니다.\n",
    "models = {\n",
    "    'Random Forest': rf_model,\n",
    "    'Gradient Boosting': gb_model,\n",
    "    'Logistic Regression': lr_model\n",
    "}\n",
    "\n",
    "# 각 모델에 대해 학습 및 평가\n",
    "for model_name, model in models.items():\n",
    "    if model_name == 'Logistic Regression':\n",
    "        # Logistic Regression은 스케일링된 데이터를 사용합니다.\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        # 앙상블 모델들은 원본 데이터를 사용해 학습합니다.\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "    # 모델의 정확도와 분류 리포트를 출력합니다.\n",
    "    # 참고: Scikit-learn - accuracy_score: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
    "    # 참고: Scikit-learn - classification_report: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, zero_division=0)\n",
    "    \n",
    "    print(f\"\\n==== {model_name} ====\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Classification Report:\\n{report}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
